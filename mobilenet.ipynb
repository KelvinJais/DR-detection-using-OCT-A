{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c9267b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install keras\n",
    "#!pip install -U scikit-learn\n",
    "#!pip install pillow\n",
    "#!pip install matplotlib\n",
    "#!pip install jupyternotify\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f2be49",
   "metadata": {
    "id": "b7f2be49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 17:12:15.841762: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-05 17:12:15.872344: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57301bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNotes for tmrw\\n\\nu reduced batch size to 16 and u saw some improvements still plateuing\\nnow ur pissed off coz accuracy is not increasing even though u put 0 data augmentation\\ntmrw I have to look into that'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notes for tmrw\n",
    "\n",
    "u reduced batch size to 16 and u saw some improvements still plateuing\n",
    "now ur pissed off coz accuracy is not increasing even though u put 0 data augmentation\n",
    "tmrw I have to look into that\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6748d",
   "metadata": {},
   "source": [
    "## Variables Being Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05de364f",
   "metadata": {
    "id": "05de364f"
   },
   "outputs": [],
   "source": [
    "#variables being used\n",
    "batch_size=32\n",
    "#val_split=0.2 #20 percent validation\n",
    "image_size=256 \n",
    "image_shape=(image_size,image_size)\n",
    "#file_directory='/root/DR no aug'\n",
    "#file_directory='/root/01DR_noDR'\n",
    "train_file_directory='/root/DR-detection-using-OCT-A/train_val_split/Training'\n",
    "validation_file_directory='/root/DR-detection-using-OCT-A/train_val_split/Validation'\n",
    "alt_train_file_directory='/root/DR-detection-using-OCT-A/train_val_split/Training_no_weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d96060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  5 17:12:17 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\r\n",
      "|  0%   37C    P8    35W / 350W |  11231MiB / 12288MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d897703e",
   "metadata": {},
   "source": [
    "## Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Xb_glLxJFLJx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xb_glLxJFLJx",
    "outputId": "8ccfce96-16b0-48ac-9b95-bb14553781f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 561 images belonging to 3 classes.\n",
      "Found 50 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.applications.mobilenet import preprocess_input #for that vgg16\n",
    "#import tensorflow as tf\n",
    "\n",
    "#from keras.applications.Xception import preprocess_input\n",
    "\n",
    "training_datagen = ImageDataGenerator( \n",
    "        preprocessing_function=preprocess_input, # use this only when using VGG16\n",
    "        #rescale=1./255,\n",
    "        rotation_range=15,#can change this\n",
    "        shear_range=0.1,#can change this\n",
    "        zoom_range=0.1, #can change this\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect',# constant,reflect,wrap,\n",
    "        )\n",
    "\n",
    "validation_datagen=ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    #rescale=1./255    \n",
    "        )\n",
    "\n",
    "#Creating our generators, no need of changing values here\n",
    "train_generator = training_datagen.flow_from_directory( #Creating our training generator \n",
    "        train_file_directory,  \n",
    "        target_size=image_shape,\n",
    "        batch_size=batch_size,\n",
    "        #color_mode='grayscale',\n",
    "        class_mode='categorical',\n",
    "        shuffle = False,\n",
    "        )\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory( #Creating our validation generator\n",
    "        validation_file_directory, \n",
    "        target_size=image_shape, \n",
    "        batch_size=batch_size,\n",
    "        #color_mode='grayscale',\n",
    "        class_mode='categorical',\n",
    "        shuffle = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6422a47",
   "metadata": {},
   "source": [
    "## Displaying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "DnUk-pHd8cOu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "DnUk-pHd8cOu",
    "outputId": "80c8e722-4ed8-4a12-d8e0-b7885b1edc12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"fig, axs=plt.subplots(ncols=4, figsize=(20,20))\\nfor i in range(4):\\n  axs[i].imshow(train_generator[i][0][0], cmap='gray', vmin=0, vmax=1)\\n#axs[0].plt.show()\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable/Disable to see 4 random images\n",
    "\"\"\"fig, axs=plt.subplots(ncols=4, figsize=(20,20))\n",
    "for i in range(4):\n",
    "  axs[i].imshow(train_generator[i][0][0], cmap='gray', vmin=0, vmax=1)\n",
    "#axs[0].plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9656c44",
   "metadata": {},
   "source": [
    "## Creating weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ifmyrLuZQNdN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifmyrLuZQNdN",
    "outputId": "7907662f-b44b-42ec-9d36-91afc3c375aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6051779935275081, 1: 0.9739583333333334, 2: 3.1166666666666667}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np ## Calculating the class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weighing = compute_class_weight(class_weight='balanced', classes=np.unique(train_generator.classes), y=train_generator.classes)\n",
    "class_weights=dict(zip(np.unique(train_generator.classes), class_weighing))\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83392058",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32d0cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense,GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "202a44ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "202a44ad",
    "outputId": "85e84d50-9fda-46f3-88df-fb8f1808d99a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 17:12:17.743165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-05 17:12:17.750147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-05 17:12:17.750373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-05 17:12:17.751238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-05 17:12:17.751401: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-05 17:12:17.751539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-05 17:12:18.164756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-05 17:12:18.164907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-05 17:12:18.165005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-05 17:12:18.165093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 124 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " mobilenet_1.00_224 (Functio  (None, 8, 8, 1024)       3228864   \n",
      " nal)                                                            \n",
      "|¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯|\n",
      "| input_1 (InputLayer)      [(None, 256, 256, 3)]     0         |\n",
      "|                                                               |\n",
      "| conv1 (Conv2D)            (None, 128, 128, 32)      864       |\n",
      "|                                                               |\n",
      "| conv1_bn (BatchNormalizatio  (None, 128, 128, 32)   128       |\n",
      "| n)                                                            |\n",
      "|                                                               |\n",
      "| conv1_relu (ReLU)         (None, 128, 128, 32)      0         |\n",
      "|                                                               |\n",
      "| conv_dw_1 (DepthwiseConv2D)  (None, 128, 128, 32)   288       |\n",
      "|                                                               |\n",
      "| conv_dw_1_bn (BatchNormaliz  (None, 128, 128, 32)   128       |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_dw_1_relu (ReLU)     (None, 128, 128, 32)      0         |\n",
      "|                                                               |\n",
      "| conv_pw_1 (Conv2D)        (None, 128, 128, 64)      2048      |\n",
      "|                                                               |\n",
      "| conv_pw_1_bn (BatchNormaliz  (None, 128, 128, 64)   256       |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_pw_1_relu (ReLU)     (None, 128, 128, 64)      0         |\n",
      "|                                                               |\n",
      "| conv_pad_2 (ZeroPadding2D)  (None, 129, 129, 64)    0         |\n",
      "|                                                               |\n",
      "| conv_dw_2 (DepthwiseConv2D)  (None, 64, 64, 64)     576       |\n",
      "|                                                               |\n",
      "| conv_dw_2_bn (BatchNormaliz  (None, 64, 64, 64)     256       |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_dw_2_relu (ReLU)     (None, 64, 64, 64)        0         |\n",
      "|                                                               |\n",
      "| conv_pw_2 (Conv2D)        (None, 64, 64, 128)       8192      |\n",
      "|                                                               |\n",
      "| conv_pw_2_bn (BatchNormaliz  (None, 64, 64, 128)    512       |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_pw_2_relu (ReLU)     (None, 64, 64, 128)       0         |\n",
      "|                                                               |\n",
      "| conv_dw_3 (DepthwiseConv2D)  (None, 64, 64, 128)    1152      |\n",
      "|                                                               |\n",
      "| conv_dw_3_bn (BatchNormaliz  (None, 64, 64, 128)    512       |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_dw_3_relu (ReLU)     (None, 64, 64, 128)       0         |\n",
      "|                                                               |\n",
      "| conv_pw_3 (Conv2D)        (None, 64, 64, 128)       16384     |\n",
      "|                                                               |\n",
      "| conv_pw_3_bn (BatchNormaliz  (None, 64, 64, 128)    512       |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_pw_3_relu (ReLU)     (None, 64, 64, 128)       0         |\n",
      "|                                                               |\n",
      "| conv_pad_4 (ZeroPadding2D)  (None, 65, 65, 128)     0         |\n",
      "|                                                               |\n",
      "| conv_dw_4 (DepthwiseConv2D)  (None, 32, 32, 128)    1152      |\n",
      "|                                                               |\n",
      "| conv_dw_4_bn (BatchNormaliz  (None, 32, 32, 128)    512       |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_dw_4_relu (ReLU)     (None, 32, 32, 128)       0         |\n",
      "|                                                               |\n",
      "| conv_pw_4 (Conv2D)        (None, 32, 32, 256)       32768     |\n",
      "|                                                               |\n",
      "| conv_pw_4_bn (BatchNormaliz  (None, 32, 32, 256)    1024      |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_pw_4_relu (ReLU)     (None, 32, 32, 256)       0         |\n",
      "|                                                               |\n",
      "| conv_dw_5 (DepthwiseConv2D)  (None, 32, 32, 256)    2304      |\n",
      "|                                                               |\n",
      "| conv_dw_5_bn (BatchNormaliz  (None, 32, 32, 256)    1024      |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_dw_5_relu (ReLU)     (None, 32, 32, 256)       0         |\n",
      "|                                                               |\n",
      "| conv_pw_5 (Conv2D)        (None, 32, 32, 256)       65536     |\n",
      "|                                                               |\n",
      "| conv_pw_5_bn (BatchNormaliz  (None, 32, 32, 256)    1024      |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_pw_5_relu (ReLU)     (None, 32, 32, 256)       0         |\n",
      "|                                                               |\n",
      "| conv_pad_6 (ZeroPadding2D)  (None, 33, 33, 256)     0         |\n",
      "|                                                               |\n",
      "| conv_dw_6 (DepthwiseConv2D)  (None, 16, 16, 256)    2304      |\n",
      "|                                                               |\n",
      "| conv_dw_6_bn (BatchNormaliz  (None, 16, 16, 256)    1024      |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_dw_6_relu (ReLU)     (None, 16, 16, 256)       0         |\n",
      "|                                                               |\n",
      "| conv_pw_6 (Conv2D)        (None, 16, 16, 512)       131072    |\n",
      "|                                                               |\n",
      "| conv_pw_6_bn (BatchNormaliz  (None, 16, 16, 512)    2048      |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_pw_6_relu (ReLU)     (None, 16, 16, 512)       0         |\n",
      "|                                                               |\n",
      "| conv_dw_7 (DepthwiseConv2D)  (None, 16, 16, 512)    4608      |\n",
      "|                                                               |\n",
      "| conv_dw_7_bn (BatchNormaliz  (None, 16, 16, 512)    2048      |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_dw_7_relu (ReLU)     (None, 16, 16, 512)       0         |\n",
      "|                                                               |\n",
      "| conv_pw_7 (Conv2D)        (None, 16, 16, 512)       262144    |\n",
      "|                                                               |\n",
      "| conv_pw_7_bn (BatchNormaliz  (None, 16, 16, 512)    2048      |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_pw_7_relu (ReLU)     (None, 16, 16, 512)       0         |\n",
      "|                                                               |\n",
      "| conv_dw_8 (DepthwiseConv2D)  (None, 16, 16, 512)    4608      |\n",
      "|                                                               |\n",
      "| conv_dw_8_bn (BatchNormaliz  (None, 16, 16, 512)    2048      |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_dw_8_relu (ReLU)     (None, 16, 16, 512)       0         |\n",
      "|                                                               |\n",
      "| conv_pw_8 (Conv2D)        (None, 16, 16, 512)       262144    |\n",
      "|                                                               |\n",
      "| conv_pw_8_bn (BatchNormaliz  (None, 16, 16, 512)    2048      |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_pw_8_relu (ReLU)     (None, 16, 16, 512)       0         |\n",
      "|                                                               |\n",
      "| conv_dw_9 (DepthwiseConv2D)  (None, 16, 16, 512)    4608      |\n",
      "|                                                               |\n",
      "| conv_dw_9_bn (BatchNormaliz  (None, 16, 16, 512)    2048      |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_dw_9_relu (ReLU)     (None, 16, 16, 512)       0         |\n",
      "|                                                               |\n",
      "| conv_pw_9 (Conv2D)        (None, 16, 16, 512)       262144    |\n",
      "|                                                               |\n",
      "| conv_pw_9_bn (BatchNormaliz  (None, 16, 16, 512)    2048      |\n",
      "| ation)                                                        |\n",
      "|                                                               |\n",
      "| conv_pw_9_relu (ReLU)     (None, 16, 16, 512)       0         |\n",
      "|                                                               |\n",
      "| conv_dw_10 (DepthwiseConv2D  (None, 16, 16, 512)    4608      |\n",
      "| )                                                             |\n",
      "|                                                               |\n",
      "| conv_dw_10_bn (BatchNormali  (None, 16, 16, 512)    2048      |\n",
      "| zation)                                                       |\n",
      "|                                                               |\n",
      "| conv_dw_10_relu (ReLU)    (None, 16, 16, 512)       0         |\n",
      "|                                                               |\n",
      "| conv_pw_10 (Conv2D)       (None, 16, 16, 512)       262144    |\n",
      "|                                                               |\n",
      "| conv_pw_10_bn (BatchNormali  (None, 16, 16, 512)    2048      |\n",
      "| zation)                                                       |\n",
      "|                                                               |\n",
      "| conv_pw_10_relu (ReLU)    (None, 16, 16, 512)       0         |\n",
      "|                                                               |\n",
      "| conv_dw_11 (DepthwiseConv2D  (None, 16, 16, 512)    4608      |\n",
      "| )                                                             |\n",
      "|                                                               |\n",
      "| conv_dw_11_bn (BatchNormali  (None, 16, 16, 512)    2048      |\n",
      "| zation)                                                       |\n",
      "|                                                               |\n",
      "| conv_dw_11_relu (ReLU)    (None, 16, 16, 512)       0         |\n",
      "|                                                               |\n",
      "| conv_pw_11 (Conv2D)       (None, 16, 16, 512)       262144    |\n",
      "|                                                               |\n",
      "| conv_pw_11_bn (BatchNormali  (None, 16, 16, 512)    2048      |\n",
      "| zation)                                                       |\n",
      "|                                                               |\n",
      "| conv_pw_11_relu (ReLU)    (None, 16, 16, 512)       0         |\n",
      "|                                                               |\n",
      "| conv_pad_12 (ZeroPadding2D)  (None, 17, 17, 512)    0         |\n",
      "|                                                               |\n",
      "| conv_dw_12 (DepthwiseConv2D  (None, 8, 8, 512)      4608      |\n",
      "| )                                                             |\n",
      "|                                                               |\n",
      "| conv_dw_12_bn (BatchNormali  (None, 8, 8, 512)      2048      |\n",
      "| zation)                                                       |\n",
      "|                                                               |\n",
      "| conv_dw_12_relu (ReLU)    (None, 8, 8, 512)         0         |\n",
      "|                                                               |\n",
      "| conv_pw_12 (Conv2D)       (None, 8, 8, 1024)        524288    |\n",
      "|                                                               |\n",
      "| conv_pw_12_bn (BatchNormali  (None, 8, 8, 1024)     4096      |\n",
      "| zation)                                                       |\n",
      "|                                                               |\n",
      "| conv_pw_12_relu (ReLU)    (None, 8, 8, 1024)        0         |\n",
      "|                                                               |\n",
      "| conv_dw_13 (DepthwiseConv2D  (None, 8, 8, 1024)     9216      |\n",
      "| )                                                             |\n",
      "|                                                               |\n",
      "| conv_dw_13_bn (BatchNormali  (None, 8, 8, 1024)     4096      |\n",
      "| zation)                                                       |\n",
      "|                                                               |\n",
      "| conv_dw_13_relu (ReLU)    (None, 8, 8, 1024)        0         |\n",
      "|                                                               |\n",
      "| conv_pw_13 (Conv2D)       (None, 8, 8, 1024)        1048576   |\n",
      "|                                                               |\n",
      "| conv_pw_13_bn (BatchNormali  (None, 8, 8, 1024)     4096      |\n",
      "| zation)                                                       |\n",
      "|                                                               |\n",
      "| conv_pw_13_relu (ReLU)    (None, 8, 8, 1024)        0         |\n",
      "¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯\n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,231,939\n",
      "Trainable params: 3,210,051\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.MobileNet(\n",
    "    weights='imagenet',\n",
    "    input_shape=(image_size, image_size, 3),\n",
    "    include_top=False)\n",
    "\n",
    "#base_model.trainable = False\n",
    "inputs = keras.Input(shape=(image_size, image_size, 3))\n",
    "\n",
    "#for layer in base_model.layers[:15]:\n",
    "#   layer.trainable = False\n",
    "#for layer in base_model.layers[15:]:\n",
    "#   layer.trainable = True\n",
    "\n",
    "x = base_model(inputs)\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "#x = keras.layers.Dropout(0.15)(x)  # Regularize with dropout\n",
    "#x=keras.layers.Dense(100)(x)\n",
    "#x=keras.layers.Dense(50)(x)\n",
    "outputs = keras.layers.Dense(3)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebce2e3",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "KBU3llMXJ7fU",
   "metadata": {
    "id": "KBU3llMXJ7fU"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.001), #SGD or adam\n",
    "              loss='categorical_crossentropy' ,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676434ca",
   "metadata": {},
   "source": [
    "### Generating Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "S9fAKukkNu8U",
   "metadata": {
    "id": "S9fAKukkNu8U"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "filepath=\"/root/DR-detection-using-OCT-A/saved_models/MobileNet_{val_accuracy:.2f}_{epoch:02d}.hdf5\"\n",
    "\n",
    "checkpoint= ModelCheckpoint(filepath,monitor='val_accuracy',verbose=0,save_best_only=True,mode='max')\n",
    "early_stop=EarlyStopping(monitor='val_accuracy',patience=100,verbose=0) #only change patience\n",
    "\n",
    "callback_list=[checkpoint]#add the callbacks used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18164a26",
   "metadata": {},
   "source": [
    "### Model.Fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "AKvvQGGHK9Ew",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKvvQGGHK9Ew",
    "outputId": "0abf91fb-43f0-4b3c-a6e8-862d660cd52d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 17:12:19.278641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-05 17:12:30.845461: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 64.00MiB (rounded to 67108864)requested by op model/mobilenet_1.00_224/conv1/Conv2D\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-04-05 17:12:30.845578: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-04-05 17:12:30.845608: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 75, Chunks in use: 73. 18.8KiB allocated for chunks. 18.2KiB in use in bin. 3.6KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845628: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 17, Chunks in use: 17. 9.0KiB allocated for chunks. 9.0KiB in use in bin. 8.4KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845648: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 18, Chunks in use: 18. 18.5KiB allocated for chunks. 18.5KiB in use in bin. 18.1KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845668: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 51, Chunks in use: 50. 106.8KiB allocated for chunks. 104.8KiB in use in bin. 101.6KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845687: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 15, Chunks in use: 14. 61.5KiB allocated for chunks. 57.5KiB in use in bin. 57.0KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845705: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 6, Chunks in use: 4. 63.0KiB allocated for chunks. 39.0KiB in use in bin. 38.0KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845725: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 6, Chunks in use: 5. 126.2KiB allocated for chunks. 102.8KiB in use in bin. 90.0KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845744: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 4, Chunks in use: 3. 149.8KiB allocated for chunks. 100.0KiB in use in bin. 86.0KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845762: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 1, Chunks in use: 1. 64.0KiB allocated for chunks. 64.0KiB in use in bin. 64.0KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845781: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 2, Chunks in use: 1. 263.5KiB allocated for chunks. 128.0KiB in use in bin. 128.0KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845799: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 2, Chunks in use: 1. 724.0KiB allocated for chunks. 256.0KiB in use in bin. 256.0KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845817: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 2, Chunks in use: 1. 1.25MiB allocated for chunks. 512.0KiB in use in bin. 512.0KiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845835: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 5, Chunks in use: 5. 5.50MiB allocated for chunks. 5.50MiB in use in bin. 5.00MiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845853: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 1. 3.00MiB allocated for chunks. 3.00MiB in use in bin. 2.00MiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845870: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 1. 4.00MiB allocated for chunks. 4.00MiB in use in bin. 4.00MiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845888: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845908: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 2, Chunks in use: 1. 48.00MiB allocated for chunks. 24.00MiB in use in bin. 24.00MiB client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845926: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 0. 61.25MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845942: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845958: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845974: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-05 17:12:30.845991: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 64.00MiB was 64.00MiB, Chunk State: \n",
      "2023-04-05 17:12:30.846006: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 130613248\n",
      "2023-04-05 17:12:30.846028: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000000 of size 1280 next 1\n",
      "2023-04-05 17:12:30.846043: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000500 of size 256 next 2\n",
      "2023-04-05 17:12:30.846056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000600 of size 256 next 3\n",
      "2023-04-05 17:12:30.846070: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000700 of size 256 next 5\n",
      "2023-04-05 17:12:30.846082: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000800 of size 256 next 6\n",
      "2023-04-05 17:12:30.846095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000900 of size 256 next 4\n",
      "2023-04-05 17:12:30.846108: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000a00 of size 256 next 7\n",
      "2023-04-05 17:12:30.846121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000b00 of size 256 next 10\n",
      "2023-04-05 17:12:30.846133: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000c00 of size 256 next 11\n",
      "2023-04-05 17:12:30.846146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000d00 of size 256 next 12\n",
      "2023-04-05 17:12:30.846159: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000e00 of size 256 next 13\n",
      "2023-04-05 17:12:30.846172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34000f00 of size 256 next 20\n",
      "2023-04-05 17:12:30.846185: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001000 of size 256 next 23\n",
      "2023-04-05 17:12:30.846197: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001100 of size 256 next 21\n",
      "2023-04-05 17:12:30.846210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001200 of size 256 next 22\n",
      "2023-04-05 17:12:30.846223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001300 of size 256 next 26\n",
      "2023-04-05 17:12:30.846235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001400 of size 256 next 27\n",
      "2023-04-05 17:12:30.846248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001500 of size 256 next 28\n",
      "2023-04-05 17:12:30.846261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001600 of size 256 next 31\n",
      "2023-04-05 17:12:30.846274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001700 of size 256 next 29\n",
      "2023-04-05 17:12:30.846287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001800 of size 256 next 30\n",
      "2023-04-05 17:12:30.846299: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001900 of size 256 next 34\n",
      "2023-04-05 17:12:30.846312: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001a00 of size 256 next 35\n",
      "2023-04-05 17:12:30.846325: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001b00 of size 256 next 18\n",
      "2023-04-05 17:12:30.846338: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001c00 of size 256 next 19\n",
      "2023-04-05 17:12:30.846351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001d00 of size 256 next 15\n",
      "2023-04-05 17:12:30.846367: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001e00 of size 256 next 16\n",
      "2023-04-05 17:12:30.846380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34001f00 of size 256 next 182\n",
      "2023-04-05 17:12:30.846394: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34002000 of size 512 next 185\n",
      "2023-04-05 17:12:30.846408: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34002200 of size 768 next 17\n",
      "2023-04-05 17:12:30.846421: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34002500 of size 256 next 8\n",
      "2023-04-05 17:12:30.846434: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34002600 of size 256 next 180\n",
      "2023-04-05 17:12:30.846447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34002700 of size 1280 next 181\n",
      "2023-04-05 17:12:30.846460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34002c00 of size 512 next 57\n",
      "2023-04-05 17:12:30.846473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34002e00 of size 512 next 56\n",
      "2023-04-05 17:12:30.846486: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34003000 of size 1024 next 47\n",
      "2023-04-05 17:12:30.846499: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34003400 of size 1024 next 59\n",
      "2023-04-05 17:12:30.846512: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34003800 of size 1024 next 41\n",
      "2023-04-05 17:12:30.846525: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34003c00 of size 256 next 42\n",
      "2023-04-05 17:12:30.846538: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34003d00 of size 256 next 43\n",
      "2023-04-05 17:12:30.846551: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34003e00 of size 512 next 46\n",
      "2023-04-05 17:12:30.846563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34004000 of size 512 next 44\n",
      "2023-04-05 17:12:30.846576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34004200 of size 512 next 45\n",
      "2023-04-05 17:12:30.846589: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34004400 of size 512 next 33\n",
      "2023-04-05 17:12:30.846602: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34004600 of size 512 next 38\n",
      "2023-04-05 17:12:30.846615: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34004800 of size 512 next 36\n",
      "2023-04-05 17:12:30.846628: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34004a00 of size 512 next 24\n",
      "2023-04-05 17:12:30.846641: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34004c00 of size 768 next 32\n",
      "2023-04-05 17:12:30.846656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34004f00 of size 256 next 48\n",
      "2023-04-05 17:12:30.846669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34005000 of size 256 next 49\n",
      "2023-04-05 17:12:30.846682: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34005100 of size 512 next 52\n",
      "2023-04-05 17:12:30.846695: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34005300 of size 512 next 50\n",
      "2023-04-05 17:12:30.846708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34005500 of size 512 next 51\n",
      "2023-04-05 17:12:30.846721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34005700 of size 512 next 55\n",
      "2023-04-05 17:12:30.846761: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34005900 of size 1024 next 65\n",
      "2023-04-05 17:12:30.846775: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34005d00 of size 1024 next 68\n",
      "2023-04-05 17:12:30.846793: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34006100 of size 256 next 69\n",
      "2023-04-05 17:12:30.846816: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34006200 of size 256 next 70\n",
      "2023-04-05 17:12:30.846839: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34006300 of size 1024 next 73\n",
      "2023-04-05 17:12:30.846860: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34006700 of size 1024 next 71\n",
      "2023-04-05 17:12:30.846873: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34006b00 of size 1024 next 82\n",
      "2023-04-05 17:12:30.846886: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34006f00 of size 256 next 189\n",
      "2023-04-05 17:12:30.846899: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34007000 of size 256 next 190\n",
      "2023-04-05 17:12:30.846915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34007100 of size 256 next 191\n",
      "2023-04-05 17:12:30.846928: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34007200 of size 256 next 192\n",
      "2023-04-05 17:12:30.846941: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34007300 of size 256 next 25\n",
      "2023-04-05 17:12:30.846955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34007400 of size 4608 next 9\n",
      "2023-04-05 17:12:30.846969: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34008600 of size 10240 next 61\n",
      "2023-04-05 17:12:30.846982: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400ae00 of size 256 next 62\n",
      "2023-04-05 17:12:30.846996: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400af00 of size 256 next 63\n",
      "2023-04-05 17:12:30.847009: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400b000 of size 1024 next 64\n",
      "2023-04-05 17:12:30.847023: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400b400 of size 2048 next 94\n",
      "2023-04-05 17:12:30.847037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400bc00 of size 3840 next 60\n",
      "2023-04-05 17:12:30.847050: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400cb00 of size 256 next 76\n",
      "2023-04-05 17:12:30.847064: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400cc00 of size 256 next 77\n",
      "2023-04-05 17:12:30.847077: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400cd00 of size 1024 next 80\n",
      "2023-04-05 17:12:30.847090: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400d100 of size 1024 next 78\n",
      "2023-04-05 17:12:30.847103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400d500 of size 1024 next 79\n",
      "2023-04-05 17:12:30.847116: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400d900 of size 1024 next 83\n",
      "2023-04-05 17:12:30.847129: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400dd00 of size 2048 next 92\n",
      "2023-04-05 17:12:30.847142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400e500 of size 2048 next 95\n",
      "2023-04-05 17:12:30.847155: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400ed00 of size 256 next 96\n",
      "2023-04-05 17:12:30.847168: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400ee00 of size 256 next 97\n",
      "2023-04-05 17:12:30.847181: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400ef00 of size 2048 next 100\n",
      "2023-04-05 17:12:30.847195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400f700 of size 2048 next 98\n",
      "2023-04-05 17:12:30.847208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3400ff00 of size 2048 next 99\n",
      "2023-04-05 17:12:30.847221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34010700 of size 3072 next 75\n",
      "2023-04-05 17:12:30.847235: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34011300 of size 9216 next 74\n",
      "2023-04-05 17:12:30.847248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34013700 of size 1024 next 85\n",
      "2023-04-05 17:12:30.847263: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34013b00 of size 1024 next 84\n",
      "2023-04-05 17:12:30.847277: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34013f00 of size 1024 next 86\n",
      "2023-04-05 17:12:30.847291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34014300 of size 256 next 175\n",
      "2023-04-05 17:12:30.847304: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34014400 of size 256 next 87\n",
      "2023-04-05 17:12:30.847317: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34014500 of size 256 next 186\n",
      "2023-04-05 17:12:30.847331: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34014600 of size 256 next 88\n",
      "2023-04-05 17:12:30.847344: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34014700 of size 256 next 89\n",
      "2023-04-05 17:12:30.847357: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34014800 of size 256 next 90\n",
      "2023-04-05 17:12:30.847370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34014900 of size 2048 next 91\n",
      "2023-04-05 17:12:30.847384: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34015100 of size 18432 next 54\n",
      "2023-04-05 17:12:30.847397: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34019900 of size 31488 next 39\n",
      "2023-04-05 17:12:30.847412: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34021400 of size 256 next 103\n",
      "2023-04-05 17:12:30.847425: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34021500 of size 256 next 104\n",
      "2023-04-05 17:12:30.847438: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34021600 of size 2048 next 107\n",
      "2023-04-05 17:12:30.847452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34021e00 of size 2048 next 105\n",
      "2023-04-05 17:12:30.847465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34022600 of size 2048 next 106\n",
      "2023-04-05 17:12:30.847478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34022e00 of size 2048 next 110\n",
      "2023-04-05 17:12:30.847491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34023600 of size 256 next 170\n",
      "2023-04-05 17:12:30.847504: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34023700 of size 256 next 171\n",
      "2023-04-05 17:12:30.847518: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34023800 of size 4096 next 174\n",
      "2023-04-05 17:12:30.847531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34024800 of size 4096 next 172\n",
      "2023-04-05 17:12:30.847544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34025800 of size 4096 next 173\n",
      "2023-04-05 17:12:30.847557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34026800 of size 256 next 200\n",
      "2023-04-05 17:12:30.847570: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd34026900 of size 256 next 201\n",
      "2023-04-05 17:12:30.847584: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34026a00 of size 512 next 202\n",
      "2023-04-05 17:12:30.847597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd34026c00 of size 256 next 204\n",
      "2023-04-05 17:12:30.847610: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34026d00 of size 256 next 205\n",
      "2023-04-05 17:12:30.847623: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34026e00 of size 256 next 206\n",
      "2023-04-05 17:12:30.847636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34026f00 of size 256 next 207\n",
      "2023-04-05 17:12:30.847650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd34027000 of size 2048 next 177\n",
      "2023-04-05 17:12:30.847664: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34027800 of size 256 next 178\n",
      "2023-04-05 17:12:30.847677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34027900 of size 3584 next 179\n",
      "2023-04-05 17:12:30.847691: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34028700 of size 2304 next 183\n",
      "2023-04-05 17:12:30.847704: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34029000 of size 5120 next 102\n",
      "2023-04-05 17:12:30.847718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3402a400 of size 18432 next 101\n",
      "2023-04-05 17:12:30.847731: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3402ec00 of size 2048 next 112\n",
      "2023-04-05 17:12:30.847744: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3402f400 of size 2048 next 111\n",
      "2023-04-05 17:12:30.847757: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3402fc00 of size 2048 next 113\n",
      "2023-04-05 17:12:30.847770: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34030400 of size 2048 next 116\n",
      "2023-04-05 17:12:30.847783: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34030c00 of size 2048 next 119\n",
      "2023-04-05 17:12:30.847796: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34031400 of size 2048 next 117\n",
      "2023-04-05 17:12:30.847809: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34031c00 of size 2048 next 118\n",
      "2023-04-05 17:12:30.847822: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34032400 of size 2048 next 121\n",
      "2023-04-05 17:12:30.847837: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34032c00 of size 2304 next 114\n",
      "2023-04-05 17:12:30.847850: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34033500 of size 18432 next 115\n",
      "2023-04-05 17:12:30.847863: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34037d00 of size 2048 next 122\n",
      "2023-04-05 17:12:30.847876: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34038500 of size 2048 next 123\n",
      "2023-04-05 17:12:30.847889: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34038d00 of size 2048 next 124\n",
      "2023-04-05 17:12:30.847902: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34039500 of size 2048 next 128\n",
      "2023-04-05 17:12:30.847915: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34039d00 of size 2048 next 126\n",
      "2023-04-05 17:12:30.847929: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3403a500 of size 2048 next 127\n",
      "2023-04-05 17:12:30.847942: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3403ad00 of size 2048 next 130\n",
      "2023-04-05 17:12:30.847955: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3403b500 of size 2048 next 131\n",
      "2023-04-05 17:12:30.847985: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3403bd00 of size 18432 next 149\n",
      "2023-04-05 17:12:30.848000: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34040500 of size 36864 next 154\n",
      "2023-04-05 17:12:30.848013: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd34049500 of size 50944 next 134\n",
      "2023-04-05 17:12:30.848026: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34055c00 of size 2048 next 125\n",
      "2023-04-05 17:12:30.848039: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34056400 of size 2048 next 53\n",
      "2023-04-05 17:12:30.848052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34056c00 of size 2048 next 132\n",
      "2023-04-05 17:12:30.848065: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34057400 of size 2048 next 135\n",
      "2023-04-05 17:12:30.848078: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34057c00 of size 2048 next 138\n",
      "2023-04-05 17:12:30.848091: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34058400 of size 2048 next 136\n",
      "2023-04-05 17:12:30.848104: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34058c00 of size 2048 next 137\n",
      "2023-04-05 17:12:30.848117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34059400 of size 2048 next 140\n",
      "2023-04-05 17:12:30.848130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34059c00 of size 2048 next 133\n",
      "2023-04-05 17:12:30.848143: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405a400 of size 2048 next 145\n",
      "2023-04-05 17:12:30.848176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405ac00 of size 2048 next 148\n",
      "2023-04-05 17:12:30.848190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405b400 of size 2048 next 146\n",
      "2023-04-05 17:12:30.848203: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405bc00 of size 2048 next 147\n",
      "2023-04-05 17:12:30.848229: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405c400 of size 2048 next 150\n",
      "2023-04-05 17:12:30.848243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405cc00 of size 2048 next 151\n",
      "2023-04-05 17:12:30.848256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405d400 of size 2048 next 152\n",
      "2023-04-05 17:12:30.848269: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405dc00 of size 2048 next 155\n",
      "2023-04-05 17:12:30.848283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405e400 of size 256 next 193\n",
      "2023-04-05 17:12:30.848296: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405e500 of size 256 next 194\n",
      "2023-04-05 17:12:30.848310: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405e600 of size 256 next 195\n",
      "2023-04-05 17:12:30.848323: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405e700 of size 256 next 196\n",
      "2023-04-05 17:12:30.848336: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405e800 of size 256 next 197\n",
      "2023-04-05 17:12:30.848349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405e900 of size 256 next 198\n",
      "2023-04-05 17:12:30.848362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405ea00 of size 256 next 199\n",
      "2023-04-05 17:12:30.848386: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405eb00 of size 256 next 144\n",
      "2023-04-05 17:12:30.848399: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405ec00 of size 2048 next 142\n",
      "2023-04-05 17:12:30.848413: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3405f400 of size 4096 next 160\n",
      "2023-04-05 17:12:30.848426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34060400 of size 4096 next 141\n",
      "2023-04-05 17:12:30.848439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34061400 of size 4096 next 176\n",
      "2023-04-05 17:12:30.848452: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd34062400 of size 4096 next 143\n",
      "2023-04-05 17:12:30.848465: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34063400 of size 256 next 156\n",
      "2023-04-05 17:12:30.848478: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34063500 of size 256 next 157\n",
      "2023-04-05 17:12:30.848491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34063600 of size 4096 next 158\n",
      "2023-04-05 17:12:30.848504: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34064600 of size 4096 next 159\n",
      "2023-04-05 17:12:30.848517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34065600 of size 4096 next 162\n",
      "2023-04-05 17:12:30.848530: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd34066600 of size 24064 next 153\n",
      "2023-04-05 17:12:30.848544: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3406c400 of size 256 next 163\n",
      "2023-04-05 17:12:30.848557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3406c500 of size 256 next 164\n",
      "2023-04-05 17:12:30.848582: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3406c600 of size 4096 next 167\n",
      "2023-04-05 17:12:30.848595: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3406d600 of size 4096 next 165\n",
      "2023-04-05 17:12:30.848608: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3406e600 of size 4096 next 166\n",
      "2023-04-05 17:12:30.848622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd3406f600 of size 138752 next 66\n",
      "2023-04-05 17:12:30.848636: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34091400 of size 8192 next 14\n",
      "2023-04-05 17:12:30.848650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34093400 of size 32768 next 184\n",
      "2023-04-05 17:12:30.848663: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd3409b400 of size 32768 next 169\n",
      "2023-04-05 17:12:30.848677: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd340a3400 of size 12288 next 187\n",
      "2023-04-05 17:12:30.848690: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd340a6400 of size 12288 next 188\n",
      "2023-04-05 17:12:30.848705: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd340a9400 of size 12288 next 168\n",
      "2023-04-05 17:12:30.848718: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd340ac400 of size 65536 next 37\n",
      "2023-04-05 17:12:30.848733: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd340bc400 of size 131072 next 58\n",
      "2023-04-05 17:12:30.848746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd340dc400 of size 479232 next 81\n",
      "2023-04-05 17:12:30.848760: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34151400 of size 262144 next 72\n",
      "2023-04-05 17:12:30.848773: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd34191400 of size 786432 next 93\n",
      "2023-04-05 17:12:30.848787: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34251400 of size 524288 next 40\n",
      "2023-04-05 17:12:30.848801: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd342d1400 of size 1572864 next 109\n",
      "2023-04-05 17:12:30.848814: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34451400 of size 1048576 next 108\n",
      "2023-04-05 17:12:30.848828: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34551400 of size 1048576 next 120\n",
      "2023-04-05 17:12:30.848841: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34651400 of size 1048576 next 129\n",
      "2023-04-05 17:12:30.848855: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34751400 of size 1048576 next 139\n",
      "2023-04-05 17:12:30.848868: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34851400 of size 3145728 next 161\n",
      "2023-04-05 17:12:30.848895: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd34b51400 of size 4194304 next 67\n",
      "2023-04-05 17:12:30.848909: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd34f51400 of size 25165824 next 203\n",
      "2023-04-05 17:12:30.848923: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7fcd36751400 of size 25165824 next 208\n",
      "2023-04-05 17:12:30.848937: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7fcd37f51400 of size 64220160 next 18446744073709551615\n",
      "2023-04-05 17:12:30.848951: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-04-05 17:12:30.848970: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 73 Chunks of size 256 totalling 18.2KiB\n",
      "2023-04-05 17:12:30.848986: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 15 Chunks of size 512 totalling 7.5KiB\n",
      "2023-04-05 17:12:30.849001: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 768 totalling 1.5KiB\n",
      "2023-04-05 17:12:30.849016: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 16 Chunks of size 1024 totalling 16.0KiB\n",
      "2023-04-05 17:12:30.849031: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2023-04-05 17:12:30.849046: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 45 Chunks of size 2048 totalling 90.0KiB\n",
      "2023-04-05 17:12:30.849069: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 2304 totalling 4.5KiB\n",
      "2023-04-05 17:12:30.849084: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3072 totalling 3.0KiB\n",
      "2023-04-05 17:12:30.849101: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3584 totalling 3.5KiB\n",
      "2023-04-05 17:12:30.849116: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3840 totalling 3.8KiB\n",
      "2023-04-05 17:12:30.849131: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 4096 totalling 48.0KiB\n",
      "2023-04-05 17:12:30.849145: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4608 totalling 4.5KiB\n",
      "2023-04-05 17:12:30.849165: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5120 totalling 5.0KiB\n",
      "2023-04-05 17:12:30.849180: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 8192 totalling 8.0KiB\n",
      "2023-04-05 17:12:30.849195: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 9216 totalling 9.0KiB\n",
      "2023-04-05 17:12:30.849210: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 10240 totalling 10.0KiB\n",
      "2023-04-05 17:12:30.849226: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 12288 totalling 12.0KiB\n",
      "2023-04-05 17:12:30.849241: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 18432 totalling 72.0KiB\n",
      "2023-04-05 17:12:30.849256: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 31488 totalling 30.8KiB\n",
      "2023-04-05 17:12:30.849272: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 32768 totalling 64.0KiB\n",
      "2023-04-05 17:12:30.849287: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 36864 totalling 36.0KiB\n",
      "2023-04-05 17:12:30.849302: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 65536 totalling 64.0KiB\n",
      "2023-04-05 17:12:30.849323: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 131072 totalling 128.0KiB\n",
      "2023-04-05 17:12:30.849338: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 262144 totalling 256.0KiB\n",
      "2023-04-05 17:12:30.849353: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 524288 totalling 512.0KiB\n",
      "2023-04-05 17:12:30.849373: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 1048576 totalling 4.00MiB\n",
      "2023-04-05 17:12:30.849388: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1572864 totalling 1.50MiB\n",
      "2023-04-05 17:12:30.849403: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3145728 totalling 3.00MiB\n",
      "2023-04-05 17:12:30.849425: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4194304 totalling 4.00MiB\n",
      "2023-04-05 17:12:30.849441: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 25165824 totalling 24.00MiB\n",
      "2023-04-05 17:12:30.849456: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 37.88MiB\n",
      "2023-04-05 17:12:30.849472: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 130613248 memory_limit_: 130613248 available bytes: 0 curr_region_allocation_bytes_: 261226496\n",
      "2023-04-05 17:12:30.849509: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       130613248\n",
      "InUse:                        39716608\n",
      "MaxInUse:                     64882432\n",
      "NumAllocs:                         476\n",
      "MaxAllocSize:                 25165824\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-04-05 17:12:30.849554: W tensorflow/tsl/framework/bfc_allocator.cc:497] *************__________________********************_________________________________________________\n",
      "2023-04-05 17:12:30.849611: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:629 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,32,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2023-04-05 17:12:30.849667: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[32,32,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model/mobilenet_1.00_224/conv1/Conv2D}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/mobilenet_1.00_224/conv1/Conv2D' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_34081/2014009322.py\", line 1, in <module>\n      get_ipython().run_cell_magic('notify', '', 'history=model.fit(\\n        train_generator,\\n        steps_per_epoch=len(train_generator.classes)//batch_size,\\n        verbose=1, \\n        epochs=300,  #change this\\n        validation_data=validation_generator,\\n        validation_steps=len(validation_generator.classes)//batch_size,\\n        callbacks=callback_list,\\n        class_weight=class_weights\\n)\\nprint(\"Done bro\")\\n')\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2475, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/jupyternotify/jupyternotify.py\", line 62, in notify\n      output = get_ipython().run_cell(cell)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_34081/1410449998.py\", line 1, in <module>\n      history=model.fit(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/mobilenet_1.00_224/conv1/Conv2D'\nOOM when allocating tensor with shape[32,32,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/mobilenet_1.00_224/conv1/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5439]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#change this\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone bro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/mobilenet_1.00_224/conv1/Conv2D' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_34081/2014009322.py\", line 1, in <module>\n      get_ipython().run_cell_magic('notify', '', 'history=model.fit(\\n        train_generator,\\n        steps_per_epoch=len(train_generator.classes)//batch_size,\\n        verbose=1, \\n        epochs=300,  #change this\\n        validation_data=validation_generator,\\n        validation_steps=len(validation_generator.classes)//batch_size,\\n        callbacks=callback_list,\\n        class_weight=class_weights\\n)\\nprint(\"Done bro\")\\n')\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2475, in run_cell_magic\n      result = fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/jupyternotify/jupyternotify.py\", line 62, in notify\n      output = get_ipython().run_cell(cell)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_34081/1410449998.py\", line 1, in <module>\n      history=model.fit(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/mobilenet_1.00_224/conv1/Conv2D'\nOOM when allocating tensor with shape[32,32,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/mobilenet_1.00_224/conv1/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5439]"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"faee0c88-c57d-49db-8a0c-a0d051f1f22a\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"faee0c88-c57d-49db-8a0c-a0d051f1f22a\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "history=model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator.classes)//batch_size,\n",
    "        verbose=1, \n",
    "        epochs=300,  #change this\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator.classes)//batch_size,\n",
    "        callbacks=callback_list,\n",
    "        class_weight=class_weights\n",
    ")\n",
    "print(\"Done bro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bbb010",
   "metadata": {},
   "source": [
    "### Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Bm4aFTAGXxZG",
   "metadata": {
    "id": "Bm4aFTAGXxZG"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#loss curve\u001b[39;00m\n\u001b[1;32m      2\u001b[0m fig, axs\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39msubplots(ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\u001b[38;5;66;03m#, figsize=(20,20))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(loss) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loss curve\n",
    "fig, axs=plt.subplots(ncols=2,figsize=(15, 5))#, figsize=(20,20))\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "axs[0].plot(epochs, loss, 'y', label='Training loss')\n",
    "axs[0].plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "axs[0].set(title='Loss', xlabel='Epochs', ylabel='Epochs');\n",
    "\n",
    "#accuracy curve\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "axs[1].plot(epochs, acc, 'y', label='Training acc')\n",
    "axs[1].plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "axs[1].set(title='Accuracy', xlabel='Epochs', ylabel='Epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad9955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"prediction_classes = np.array([])\n",
    "true_classes =  np.array([])\n",
    "i=0\n",
    "for x, y in validation_generator:\n",
    "    if i==len(validation_generator.classes):\n",
    "        break    \n",
    "    i=i+1\n",
    "    prediction_classes = np.concatenate([prediction_classes,np.argmax(model.predict(x,verbose=0), axis = -1)])\n",
    "    true_classes = np.concatenate([true_classes, np.argmax(y, axis=-1)])\n",
    "print(classification_report(true_classes, prediction_classes))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28026f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('to_continue.h5')\n",
    "#continue_model=load_model('to_continue.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed3a7c",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9152a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "#model = load_model('/root/44-0.82.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8076d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model=load_model(\".hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1uTXxiYXZ8Tl",
   "metadata": {
    "id": "1uTXxiYXZ8Tl",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_eval=validation_generator\n",
    "model_eval=model\n",
    "results=model_eval.evaluate_generator(data_eval, steps=len(data_eval.classes)//batch_size)\n",
    "print(\"Loss and accuracy are\", results)\n",
    "Y_pred = model_eval.predict_generator(data_eval, steps=len(data_eval.classes)//batch_size+1)\n",
    "#print(train_generator.classes)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "#print(train_generator.classes)\n",
    "#print(y_pred)\n",
    "#print(X)\n",
    "        \n",
    "print('Confusion Matrix')\n",
    "cm=confusion_matrix(data_eval.classes,y_pred)\n",
    "target_names = ['NoDR', 'mildDR','seriousDR']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "print('Classification Report')\n",
    "\n",
    "print(classification_report(data_eval.classes,y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
